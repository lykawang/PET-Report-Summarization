# Evaluating PET impressions generated by Large Language Models :bookmark_tabs:

This repository contains the code for evaluating the quality of PET impressions. 

We appreciate the previous works that implemented the evaluation metrics 

## ⚖️ Acknowledgments

Parts of the code in this repository were adapted from [**SummEval**](#https://github.com/Yale-LILY/SummEval), [**BARTScore**](#https://github.com/neulab/BARTScore), [**UniEval**](#https://github.com/maszhongming/UniEval), [**PRISM**](#https://github.com/thompsonb/prism). We sincerely thank the authors of these repositories for their contributions to the community.
